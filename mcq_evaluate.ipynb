{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "from os import getenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the context from a text file \n",
    "context = \"\"\n",
    "with open(\"content.txt\", \"r\") as f:\n",
    "    context = f.read()\n",
    "    \n",
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the learning outcomes from a text file \n",
    "assessment_los = \"\"\n",
    "with open(\"A1_los.txt\", \"r\") as f:\n",
    "    assessment_los = f.read()\n",
    "    \n",
    "# print(assessment_los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcqs = generate_mcqs(context, assessment_los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MCQs back from the text file\n",
    "with open(\"generated_mcqs.txt\", \"r\") as f:\n",
    "    mcqs_read = f.read().split(\"\\n\\n\")\n",
    "    # Remove empty strings\n",
    "    mcqs_read = [mcq for mcq in mcqs_read if mcq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q1. What is the first step in the six-step problem-solving process?  \\nA) Analyse the problem  \\nB) Identify the problem  \\nC) Implement the solution  \\nD) Generate potential solutions  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q2. Which of the following best defines wicked problems?  \\nA) Problems that have simple solutions.  \\nB) Problems that occur regularly and are easy to solve.  \\nC) Problems difficult to define, with no clear solutions.  \\nD) Problems that always have one correct answer.  \\nCorrect Answer: C  \\nDifficulty: Medium  ',\n",
       " 'Q3. Which programming construct is used to repeatedly execute a block of code while a condition is true?  \\nA) for loop  \\nB) while loop  \\nC) if statement  \\nD) elif statement  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q4. What does the Python function `type()` do?  \\nA) Converts a variable into a different type.  \\nB) Checks the size of the variable.  \\nC) Returns the data type of a variable.  \\nD) Assigns a type to the variable.  \\nCorrect Answer: C  \\nDifficulty: Easy  ',\n",
       " 'Q5. Which operator has the highest precedence in Python?  \\nA) Addition `+`  \\nB) Parentheses `()`  \\nC) Multiplication `*`  \\nD) Division `/`  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q6. What does the `input()` function return?  \\nA) Integer  \\nB) Float  \\nC) String  \\nD) Boolean  \\nCorrect Answer: C  \\nDifficulty: Easy  ',\n",
       " 'Q7. In Python, how can a string be enclosed to be defined correctly?  \\nA) Single quotes (\\'), double quotes (\"), or triple quotes (\"\"\" \"\"\").  \\nB) Only single quotes (\\' \\').  \\nC) Only double quotes (\" \").  \\nD) Only triple quotes (\"\"\" \"\"\").  \\nCorrect Answer: A  \\nDifficulty: Easy  ',\n",
       " \"Q8. Why is Python considered a strongly typed language?  \\nA) Variables must have a pre-defined type.  \\nB) Variables have a type, and the type matters during operations.  \\nC) Python doesn't allow type checking.  \\nD) Python doesn't support reassigning variables.  \\nCorrect Answer: B  \\nDifficulty: Medium  \",\n",
       " 'Q9. What will the output of the following code be?  \\n```Python  \\nnum = 10 // 3  \\nprint(num)  \\n```  \\nA) 3.33  \\nB) 3  \\nC) 3.0  \\nD) Error  \\nCorrect Answer: B  \\nDifficulty: Medium  ',\n",
       " 'Q10. Which mode is used to open an existing file for appending at the end?  \\nA) w  \\nB) r+  \\nC) a  \\nD) w+  \\nCorrect Answer: C  \\nDifficulty: Medium  ',\n",
       " 'Q11. Which Python keyword is used to terminate a loop prematurely?  \\nA) continue  \\nB) break  \\nC) pass  \\nD) return  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q12. In the context of Python lists, what does the method `.append()` do?  \\nA) Removes an item from the list.  \\nB) Adds an item to the beginning of the list.  \\nC) Adds an item to the end of the list.  \\nD) Inserts an item at a specific position.  \\nCorrect Answer: C  \\nDifficulty: Easy  ',\n",
       " 'Q13. What is the result of the following Python statement?  \\n```Python  \\n\"Hello\" * 3  \\n```  \\nA) \"HelloHelloHello\"  \\nB) \"Hello 3\"  \\nC) Error  \\nD) \"Hello+Hello+Hello\"  \\nCorrect Answer: A  \\nDifficulty: Easy  ',\n",
       " 'Q14. Which Python statement can be used to iterate over items in a sequence?  \\nA) if  \\nB) for  \\nC) while  \\nD) elif  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q15. What will the following code print?  \\n```Python  \\nnumber = 5  \\nif number != 5:  \\n    print(\"Not Five\")  \\nelse:  \\n    print(\"Five\")  \\n```  \\nA) Not Five  \\nB) Five  \\nC) Error: Syntax Issue  \\nD) Nothing  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q16. What does `len()` function do in Python?  \\nA) Finds the size of integers.  \\nB) Determines the length of sequences.  \\nC) Deletes an element of a sequence.  \\nD) Multiplies strings by a given number.  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q17. Which of the following is an immutable data structure in Python?  \\nA) Lists  \\nB) Strings  \\nC) Dictionaries  \\nD) Tuples  \\nCorrect Answer: D  \\nDifficulty: Medium  ',\n",
       " 'Q18. Which best describes the main advantage of tuples over lists?  \\nA) Tuples are faster and immutable.  \\nB) Tuples support more features than lists.  \\nC) Tuples can only contain strings.  \\nD) Tuples cannot store multiple data types.  \\nCorrect Answer: A  \\nDifficulty: Medium  ',\n",
       " 'Q19. How do you create a comment in Python?  \\nA) /* comment */  \\nB) # comment  \\nC) // comment  \\nD) <!-- comment -->  \\nCorrect Answer: B  \\nDifficulty: Easy  ',\n",
       " 'Q20. What will the following code snippet return?  \\n```Python  \\n\"isalpha\".isalpha()  \\n```  \\nA) True  \\nB) False  \\nC) Error  \\nD) None  \\nCorrect Answer: A  \\nDifficulty: Medium  ',\n",
       " 'Q21. If a file is opened using the `w` mode, what will happen if the file already exists?  \\nA) Raise an error.  \\nB) Add content to the end of the existing file.  \\nC) Overwrite the fileâ€™s content.  \\nD) Open the file without modification.  \\nCorrect Answer: C  \\nDifficulty: Medium  ',\n",
       " 'Q22. What is the result of the Python expression `\"Python\"[0:4]`?  \\nA) \"Py\"  \\nB) \"Pyth\"  \\nC) \"Python\"  \\nD) \"Pyto\"  \\nCorrect Answer: B  \\nDifficulty: Medium  ',\n",
       " 'Q23. What does the following line of code do?  \\n```Python  \\nfile = open(\"example.txt\", \"r\")  \\n```  \\nA) Creates a new file named \"example.txt\".  \\nB) Opens the file \"example.txt\" for reading.  \\nC) Writes data to the file \"example.txt\".  \\nD) Appends data to the file \"example.txt\".  \\nCorrect Answer: B  \\nDifficulty: Medium  ',\n",
       " 'Q24. How do you convert a string `\"42\"` to an integer in Python?  \\nA) int(42)  \\nB) str(42)  \\nC) int(\"42\")  \\nD) str(\"42\")  \\nCorrect Answer: C  \\nDifficulty: Easy  ',\n",
       " 'Q25. What will the following line print?  \\n```Python  \\nprint(list(range(5, 10, 2)))  \\n```  \\nA) [5, 7, 9]  \\nB) [6, 8, 10]  \\nC) Error  \\nD) [5, 6, 7, 8, 9, 10]  \\nCorrect Answer: A  \\nDifficulty: Medium  ',\n",
       " 'Q26. What is the purpose of the `find()` method in strings?  \\nA) To find data in a file.  \\nB) To locate the index of a substring within a string.  \\nC) To split a string.  \\nD) To replace part of a string.  \\nCorrect Answer: B  \\nDifficulty: Medium  ',\n",
       " 'Q27. Why might you use a \"do-while\" equivalent loop in Python?  \\nA) To ensure the loop executes once before the condition is checked.  \\nB) To create an infinite loop.  \\nC) To handle unexpected errors.  \\nD) To replace an `if` statement.  \\nCorrect Answer: A  \\nDifficulty: Medium  ',\n",
       " 'Q28. Which access mode should you use to write data without overwriting existing content in a file?  \\nA) r  \\nB) w  \\nC) a  \\nD) r+  \\nCorrect Answer: C  \\nDifficulty: Medium  ',\n",
       " 'Q29. What will the statement `beatles[2]` return if `beatles = [\"John\", \"Paul\", \"George\", \"Ringo\"]`?  \\nA) \"John\"  \\nB) \"Paul\"  \\nC) \"George\"  \\nD) \"Ringo\"  \\nCorrect Answer: C  \\nDifficulty: Easy  ',\n",
       " 'Q30. Why should we use mnemonic variable names in programming?  \\nA) To make the code run faster.  \\nB) To reduce the amount of memory used.  \\nC) To improve code readability and maintainability.  \\nD) To reduce the size of variable names.  \\nCorrect Answer: C  \\nDifficulty: Easy  ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcqs_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_relevance(mcqs, context):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Define the relevance criterion configuration\n",
    "    criteria_config = {\n",
    "        \"name\": \"Relevance to Provided Context\",\n",
    "        \"score_key\": \"relevance_score\",\n",
    "        \"justification_key\": \"relevance_justification\",\n",
    "        \"description\": \"\"\"\n",
    "        1. Relevance to Provided Context\n",
    "           - 1 (Good): Directly ties to key concepts, examples, or terminology from the provided context\n",
    "           - 0 (Poor): Irrelevant or misaligned with the context (e.g., introduces unrelated topics)\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    for question in mcqs:\n",
    "        # Clean the question to remove problematic characters\n",
    "        clean_question = question.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        clean_question = clean_question.replace('\\\\', '\\\\\\\\')\n",
    "        clean_question = clean_question.replace('\"', '\\\\\"')\n",
    "        \n",
    "        # Extract only the first line as a short question summary\n",
    "        question_summary = clean_question.split('  ')[0] if '  ' in clean_question else clean_question\n",
    "        if len(question_summary) > 50:\n",
    "            question_summary = question_summary[:47] + \"...\"\n",
    "        \n",
    "        # Build the prompt for relevance evaluation only\n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following MCQ based on the provided Context.\n",
    "        Your evaluation should follow the Evaluation Rubric below with scores of 0 (Poor) or 2 (Good).\n",
    "        Return your evaluation in valid JSON format with scores and justifications.\n",
    "        \n",
    "        Context: {context}\n",
    "\n",
    "        MCQ: {clean_question}\n",
    "        \n",
    "        Evaluation Rubric:\n",
    "        {criteria_config[\"description\"]}\n",
    "\n",
    "        Required JSON format:\n",
    "        {{\n",
    "            \"question\": \"{question_summary}\",\n",
    "            \"evaluations\": {{\n",
    "                \"{criteria_config[\"score_key\"]}\": 0-1,\n",
    "                \"{criteria_config[\"justification_key\"]}\": \"justification text\"\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        Follow strictly the JSON format and do not add anything extra or markdown.\n",
    "        Ensure all text is properly escaped for JSON.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-chat:free\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an MCQ evaluation assistant. Always respond with valid JSON in the exact format specified.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # Get the response content and attempt to clean it further if needed\n",
    "            response_content = response.choices[0].message.content\n",
    "            \n",
    "            # Try to fix common JSON issues before parsing\n",
    "            response_content = response_content.strip()\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content.replace(\"```json\", \"\", 1)\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content.replace(\"```\", \"\", 1)\n",
    "            response_content = response_content.strip()\n",
    "            \n",
    "            eval_data = json.loads(response_content)\n",
    "            \n",
    "            # Create result dictionary using the original question to preserve all information\n",
    "            result = {'Question': question}\n",
    "            result[f'{criteria_config[\"name\"]} Score'] = eval_data['evaluations'][criteria_config[\"score_key\"]]\n",
    "            result[f'{criteria_config[\"name\"]} Justification'] = eval_data['evaluations'][criteria_config[\"justification_key\"]]\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content[:100]}...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Relevance to Provided Context Score</th>\n",
       "      <th>Relevance to Provided Context Justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1. What is the first step in the six-step pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the provided con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2. Which of the following best defines wicked...</td>\n",
       "      <td>1</td>\n",
       "      <td>The MCQ directly ties to the provided context,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3. Which programming construct is used to rep...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the topic of loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4. What does the Python function `type()` do?...</td>\n",
       "      <td>1</td>\n",
       "      <td>The MCQ directly ties to the concept of data t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5. Which operator has the highest precedence ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the Operator Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q6. What does the `input()` function return?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to key concepts fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q7. In Python, how can a string be enclosed to...</td>\n",
       "      <td>1</td>\n",
       "      <td>The MCQ directly ties to the context provided,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q8. Why is Python considered a strongly typed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the provided con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q9. What will the output of the following code...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context, as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q10. Which mode is used to open an existing fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q11. Which Python keyword is used to terminate...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the topic of loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q12. In the context of Python lists, what does...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the key concept ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q13. What is the result of the following Pytho...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context, spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q14. Which Python statement can be used to ite...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q15. What will the following code print?  \\n``...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the key concepts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q16. What does `len()` function do in Python? ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The `len()` function in Python determines the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q17. Which of the following is an immutable da...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the key concept ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q18. Which best describes the main advantage o...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context's di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q19. How do you create a comment in Python?  \\...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to a key concept in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q20. What will the following code snippet retu...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the provided con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Q21. If a file is opened using the `w` mode, w...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly relates to the context p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q22. What is the result of the Python expressi...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the concept of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q23. What does the following line of code do? ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the provided con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q24. How do you convert a string `\"42\"` to an ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the concept of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q25. What will the following line print?  \\n``...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the concept of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q26. What is the purpose of the `find()` metho...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the key concept ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q27. Why might you use a \"do-while\" equivalent...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question is directly relevant to the conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q28. Which access mode should you use to write...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q29. What will the statement `beatles[2]` retu...</td>\n",
       "      <td>1</td>\n",
       "      <td>The question directly ties to the context prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q30. Why should we use mnemonic variable names...</td>\n",
       "      <td>0</td>\n",
       "      <td>The MCQ does not directly tie to any key conce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0   Q1. What is the first step in the six-step pro...   \n",
       "1   Q2. Which of the following best defines wicked...   \n",
       "2   Q3. Which programming construct is used to rep...   \n",
       "3   Q4. What does the Python function `type()` do?...   \n",
       "4   Q5. Which operator has the highest precedence ...   \n",
       "5   Q6. What does the `input()` function return?  ...   \n",
       "6   Q7. In Python, how can a string be enclosed to...   \n",
       "7   Q8. Why is Python considered a strongly typed ...   \n",
       "8   Q9. What will the output of the following code...   \n",
       "9   Q10. Which mode is used to open an existing fi...   \n",
       "10  Q11. Which Python keyword is used to terminate...   \n",
       "11  Q12. In the context of Python lists, what does...   \n",
       "12  Q13. What is the result of the following Pytho...   \n",
       "13  Q14. Which Python statement can be used to ite...   \n",
       "14  Q15. What will the following code print?  \\n``...   \n",
       "15  Q16. What does `len()` function do in Python? ...   \n",
       "16  Q17. Which of the following is an immutable da...   \n",
       "17  Q18. Which best describes the main advantage o...   \n",
       "18  Q19. How do you create a comment in Python?  \\...   \n",
       "19  Q20. What will the following code snippet retu...   \n",
       "20  Q21. If a file is opened using the `w` mode, w...   \n",
       "21  Q22. What is the result of the Python expressi...   \n",
       "22  Q23. What does the following line of code do? ...   \n",
       "23  Q24. How do you convert a string `\"42\"` to an ...   \n",
       "24  Q25. What will the following line print?  \\n``...   \n",
       "25  Q26. What is the purpose of the `find()` metho...   \n",
       "26  Q27. Why might you use a \"do-while\" equivalent...   \n",
       "27  Q28. Which access mode should you use to write...   \n",
       "28  Q29. What will the statement `beatles[2]` retu...   \n",
       "29  Q30. Why should we use mnemonic variable names...   \n",
       "\n",
       "    Relevance to Provided Context Score  \\\n",
       "0                                     1   \n",
       "1                                     1   \n",
       "2                                     1   \n",
       "3                                     1   \n",
       "4                                     1   \n",
       "5                                     1   \n",
       "6                                     1   \n",
       "7                                     1   \n",
       "8                                     1   \n",
       "9                                     1   \n",
       "10                                    1   \n",
       "11                                    1   \n",
       "12                                    1   \n",
       "13                                    1   \n",
       "14                                    1   \n",
       "15                                    1   \n",
       "16                                    1   \n",
       "17                                    1   \n",
       "18                                    1   \n",
       "19                                    1   \n",
       "20                                    1   \n",
       "21                                    1   \n",
       "22                                    1   \n",
       "23                                    1   \n",
       "24                                    1   \n",
       "25                                    1   \n",
       "26                                    1   \n",
       "27                                    1   \n",
       "28                                    1   \n",
       "29                                    0   \n",
       "\n",
       "          Relevance to Provided Context Justification  \n",
       "0   The question directly ties to the provided con...  \n",
       "1   The MCQ directly ties to the provided context,...  \n",
       "2   The question directly ties to the topic of loo...  \n",
       "3   The MCQ directly ties to the concept of data t...  \n",
       "4   The question directly ties to the Operator Pre...  \n",
       "5   The question directly ties to key concepts fro...  \n",
       "6   The MCQ directly ties to the context provided,...  \n",
       "7   The question directly ties to the provided con...  \n",
       "8   The question directly ties to the context, as ...  \n",
       "9   The question directly ties to the context prov...  \n",
       "10  The question directly ties to the topic of loo...  \n",
       "11  The question directly ties to the key concept ...  \n",
       "12  The question directly ties to the context, spe...  \n",
       "13  The question directly ties to the context prov...  \n",
       "14  The question directly ties to the key concepts...  \n",
       "15  The `len()` function in Python determines the ...  \n",
       "16  The question directly ties to the key concept ...  \n",
       "17  The question directly ties to the context's di...  \n",
       "18  The question directly ties to a key concept in...  \n",
       "19  The question directly ties to the provided con...  \n",
       "20  The question directly relates to the context p...  \n",
       "21  The question directly ties to the concept of s...  \n",
       "22  The question directly ties to the provided con...  \n",
       "23  The question directly ties to the concept of t...  \n",
       "24  The question directly ties to the concept of t...  \n",
       "25  The question directly ties to the key concept ...  \n",
       "26  The question is directly relevant to the conte...  \n",
       "27  The question directly ties to the context prov...  \n",
       "28  The question directly ties to the context prov...  \n",
       "29  The MCQ does not directly tie to any key conce...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_df = evaluate_relevance(mcqs_read, context)\n",
    "relevance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_df.to_csv('relevance_evaluation3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lo(mcqs, assessment_los):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Define the relevance criterion configuration\n",
    "    criteria_config = {\n",
    "        \"name\": \"Alignment with Learning Outcomes\",\n",
    "            \"score_key\": \"learning_outcome_score\",\n",
    "            \"justification_key\": \"learning_outcome_justification\",\n",
    "            \"description\": \"\"\"\n",
    "            2. Alignment with Learning Outcomes\n",
    "               - 2 (Good): Tests a specific skill/knowledge stated in the learning outcomes\n",
    "               - 1 (Fair): Vaguely related to outcomes but lacks specificity or depth\n",
    "               - 0 (Poor): Fails to address any stated learning outcome\n",
    "            \"\"\"\n",
    "    }\n",
    "    \n",
    "    for question in mcqs:\n",
    "        # Clean the question to remove problematic characters\n",
    "        clean_question = question.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        clean_question = clean_question.replace('\\\\', '\\\\\\\\')\n",
    "        clean_question = clean_question.replace('\"', '\\\\\"')\n",
    "        \n",
    "        # Extract only the first line as a short question summary\n",
    "        question_summary = clean_question.split('  ')[0] if '  ' in clean_question else clean_question\n",
    "        if len(question_summary) > 50:\n",
    "            question_summary = question_summary[:47] + \"...\"\n",
    "        \n",
    "        # Build the prompt for relevance evaluation only\n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following MCQ based on the Learning Outcomes below.\n",
    "        Your evaluation should follow the Evaluation Rubric below with scores of 0 (Poor), 1 (Fair), or 2 (Good).\n",
    "        Return your evaluation in valid JSON format with scores and justifications. \n",
    "        In the justification, specify when the MCQ aligns with one or more of the learning outcomes. If so, mention which learning outcomes are relevant.\n",
    "        \n",
    "        Learning Outcomes: {assessment_los}\n",
    "\n",
    "        MCQ: {clean_question}\n",
    "        \n",
    "        Evaluation Rubric:\n",
    "        {criteria_config[\"description\"]}\n",
    "\n",
    "        Required JSON format:\n",
    "        {{\n",
    "            \"question\": \"{question_summary}\",\n",
    "            \"evaluations\": {{\n",
    "                \"{criteria_config[\"score_key\"]}\": 0-2,\n",
    "                \"{criteria_config[\"justification_key\"]}\": \"justification text\"\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        Follow strictly the JSON format and do not add anything extra or markdown.\n",
    "        Ensure all text is properly escaped for JSON.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-chat:free\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an MCQ evaluation assistant. Always respond with valid JSON in the exact format specified.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # Get the response content and attempt to clean it further if needed\n",
    "            response_content = response.choices[0].message.content\n",
    "            \n",
    "            # Try to fix common JSON issues before parsing\n",
    "            response_content = response_content.strip()\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content.replace(\"```json\", \"\", 1)\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content.replace(\"```\", \"\", 1)\n",
    "            response_content = response_content.strip()\n",
    "            \n",
    "            eval_data = json.loads(response_content)\n",
    "            \n",
    "            # Create result dictionary using the original question to preserve all information\n",
    "            result = {'Question': question}\n",
    "            result[f'{criteria_config[\"name\"]} Score'] = eval_data['evaluations'][criteria_config[\"score_key\"]]\n",
    "            result[f'{criteria_config[\"name\"]} Justification'] = eval_data['evaluations'][criteria_config[\"justification_key\"]]\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content[:100]}...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lo_df \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_lo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmcqs_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massessment_los\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m lo_df\n",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m, in \u001b[0;36mevaluate_lo\u001b[1;34m(mcqs, assessment_los)\u001b[0m\n\u001b[0;32m     30\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124mEvaluate the following MCQ based on the Learning Outcomes below.\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124mYour evaluation should follow the Evaluation Rubric below with scores of 0 (Poor), 1 (Fair), or 2 (Good).\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124mEnsure all text is properly escaped for JSON.\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek/deepseek-chat:free\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an MCQ evaluation assistant. Always respond with valid JSON in the exact format specified.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Get the response content and attempt to clean it further if needed\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     response_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\openai\\_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 991\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    997\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_client.py:940\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    939\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 940\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_client.py:934\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 934\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_models.py:815\u001b[0m, in \u001b[0;36mResponse.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_bytes())\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_models.py:831\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    829\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 831\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_models.py:885\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    882\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 885\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_client.py:127\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpx\\_transports\\default.py:116\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 116\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:367\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:363\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:349\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:341\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 341\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:210\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    207\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\HSKhd\\miniconda3\\envs\\torch\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lo_df = evaluate_lo(mcqs_read, assessment_los)\n",
    "lo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_df.to_csv('lo_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_distractor(mcqs, context):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Define the relevance criterion configuration\n",
    "    criteria_config = {\n",
    "        \"name\": \"Distractor Quality\",\n",
    "            \"score_key\": \"distractor_score\",\n",
    "            \"justification_key\": \"distractor_justification\",\n",
    "            \"description\": \"\"\"\n",
    "            3. Distractor Quality\n",
    "               - 2 (Good): Distractors are plausible and reflect common misconceptions/mistakes\n",
    "               - 1 (Fair): Some distractors are too obvious or lack real-world relevance\n",
    "               - 0 (Poor): Distractors are illogical, nonsensical, or non-functional\n",
    "            \"\"\"\n",
    "    }\n",
    "    \n",
    "    for question in mcqs:\n",
    "        # Clean the question to remove problematic characters\n",
    "        clean_question = question.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        clean_question = clean_question.replace('\\\\', '\\\\\\\\')\n",
    "        clean_question = clean_question.replace('\"', '\\\\\"')\n",
    "        \n",
    "        # Extract only the first line as a short question summary\n",
    "        question_summary = clean_question.split('  ')[0] if '  ' in clean_question else clean_question\n",
    "        if len(question_summary) > 50:\n",
    "            question_summary = question_summary[:47] + \"...\"\n",
    "        \n",
    "        # Build the prompt for relevance evaluation only\n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following MCQ based on the following Evaluation Rubric below with scores of 0 (Poor), 1 (Fair), or 2 (Good).\n",
    "        Return your evaluation in valid JSON format with scores and justifications.\n",
    "        \n",
    "        Context: {context}\n",
    "\n",
    "        MCQ: {clean_question}\n",
    "        \n",
    "        Evaluation Rubric:\n",
    "        {criteria_config[\"description\"]}\n",
    "\n",
    "        Required JSON format:\n",
    "        {{\n",
    "            \"question\": \"{question_summary}\",\n",
    "            \"evaluations\": {{\n",
    "                \"{criteria_config[\"score_key\"]}\": 0-1,\n",
    "                \"{criteria_config[\"justification_key\"]}\": \"justification text\"\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        Follow strictly the JSON format and do not add anything extra or markdown.\n",
    "        Ensure all text is properly escaped for JSON.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-chat:free\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an MCQ evaluation assistant. Always respond with valid JSON in the exact format specified.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # Get the response content and attempt to clean it further if needed\n",
    "            response_content = response.choices[0].message.content\n",
    "            \n",
    "            # Try to fix common JSON issues before parsing\n",
    "            response_content = response_content.strip()\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content.replace(\"```json\", \"\", 1)\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content.replace(\"```\", \"\", 1)\n",
    "            response_content = response_content.strip()\n",
    "            \n",
    "            eval_data = json.loads(response_content)\n",
    "            \n",
    "            # Create result dictionary using the original question to preserve all information\n",
    "            result = {'Question': question}\n",
    "            result[f'{criteria_config[\"name\"]} Score'] = eval_data['evaluations'][criteria_config[\"score_key\"]]\n",
    "            result[f'{criteria_config[\"name\"]} Justification'] = eval_data['evaluations'][criteria_config[\"justification_key\"]]\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content[:100]}...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clarity(mcqs, context):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Define the relevance criterion configuration\n",
    "    criteria_config = {\n",
    "        \"name\": \"Clarity and Precision\",\n",
    "        \"score_key\": \"clarity_score\",\n",
    "        \"justification_key\": \"clarity_justification\",\n",
    "        \"description\": \"\"\"\n",
    "        4. Clarity and Precision\n",
    "            - 2 (Good): Unambiguous wording, code examples are syntactically correct, and only one correct answer\n",
    "            - 1 (Fair): Minor ambiguities or typos, but answerable\n",
    "            - 0 (Poor): Confusing wording, code errors, or multiple valid answers\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    for question in mcqs:\n",
    "        # Clean the question to remove problematic characters\n",
    "        clean_question = question.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        clean_question = clean_question.replace('\\\\', '\\\\\\\\')\n",
    "        clean_question = clean_question.replace('\"', '\\\\\"')\n",
    "        \n",
    "        # Extract only the first line as a short question summary\n",
    "        question_summary = clean_question.split('  ')[0] if '  ' in clean_question else clean_question\n",
    "        if len(question_summary) > 50:\n",
    "            question_summary = question_summary[:47] + \"...\"\n",
    "        \n",
    "        # Build the prompt for relevance evaluation only\n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following MCQ based on the following Evaluation Rubric below with scores of 0 (Poor), 1 (Fair), or 2 (Good).\n",
    "        Return your evaluation in valid JSON format with scores and justifications.\n",
    "        \n",
    "        Context: {context}\n",
    "\n",
    "        MCQ: {clean_question}\n",
    "        \n",
    "        Evaluation Rubric:\n",
    "        {criteria_config[\"description\"]}\n",
    "\n",
    "        Required JSON format:\n",
    "        {{\n",
    "            \"question\": \"{question_summary}\",\n",
    "            \"evaluations\": {{\n",
    "                \"{criteria_config[\"score_key\"]}\": 0-1,\n",
    "                \"{criteria_config[\"justification_key\"]}\": \"justification text\"\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        Follow strictly the JSON format and do not add anything extra or markdown.\n",
    "        Ensure all text is properly escaped for JSON.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-chat:free\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an MCQ evaluation assistant. Always respond with valid JSON in the exact format specified.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # Get the response content and attempt to clean it further if needed\n",
    "            response_content = response.choices[0].message.content\n",
    "            \n",
    "            # Try to fix common JSON issues before parsing\n",
    "            response_content = response_content.strip()\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content.replace(\"```json\", \"\", 1)\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content.replace(\"```\", \"\", 1)\n",
    "            response_content = response_content.strip()\n",
    "            \n",
    "            eval_data = json.loads(response_content)\n",
    "            \n",
    "            # Create result dictionary using the original question to preserve all information\n",
    "            result = {'Question': question}\n",
    "            result[f'{criteria_config[\"name\"]} Score'] = eval_data['evaluations'][criteria_config[\"score_key\"]]\n",
    "            result[f'{criteria_config[\"name\"]} Justification'] = eval_data['evaluations'][criteria_config[\"justification_key\"]]\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content[:100]}...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_difficulty(mcqs, context):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Define the relevance criterion configuration\n",
    "    criteria_config = {\n",
    "        \"name\": \"Difficulty Level\",\n",
    "        \"score_key\": \"difficulty_level\",\n",
    "        \"justification_key\": \"difficulty_justification\",\n",
    "        \"description\": \"\"\"\n",
    "        5. Difficulty Level (assign one of these categories and explain your reasoning)\n",
    "            - Difficult: Promotes high-level thinking, problem-solving, or evaluation\n",
    "            - Medium: Requires application of knowledge in familiar scenarios, may involve debugging simple code or interpreting logic\n",
    "            - Easy: Tests basic recall or straightforward application\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    for question in mcqs:\n",
    "        # Clean the question to remove problematic characters\n",
    "        clean_question = question.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        clean_question = clean_question.replace('\\\\', '\\\\\\\\')\n",
    "        clean_question = clean_question.replace('\"', '\\\\\"')\n",
    "        \n",
    "        # Extract only the first line as a short question summary\n",
    "        question_summary = clean_question.split('  ')[0] if '  ' in clean_question else clean_question\n",
    "        if len(question_summary) > 50:\n",
    "            question_summary = question_summary[:47] + \"...\"\n",
    "        \n",
    "        # Build the prompt for relevance evaluation only\n",
    "        prompt = f\"\"\"\n",
    "        Evaluate the following MCQ based on the following Evaluation Rubric below with grades of Easy, Medium, or Difficult.\n",
    "        Return your evaluation in valid JSON format with grades and justifications.\n",
    "        \n",
    "        Context: {context}\n",
    "\n",
    "        MCQ: {clean_question}\n",
    "        \n",
    "        Evaluation Rubric:\n",
    "        {criteria_config[\"description\"]}\n",
    "\n",
    "        Required JSON format:\n",
    "        {{\n",
    "            \"question\": \"{question_summary}\",\n",
    "            \"evaluations\": {{\n",
    "                \"{criteria_config[\"score_key\"]}\": 0-1,\n",
    "                \"{criteria_config[\"justification_key\"]}\": \"justification text\"\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        Follow strictly the JSON format and do not add anything extra or markdown.\n",
    "        Ensure all text is properly escaped for JSON.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek/deepseek-chat:free\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an MCQ evaluation assistant. Always respond with valid JSON in the exact format specified.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # Get the response content and attempt to clean it further if needed\n",
    "            response_content = response.choices[0].message.content\n",
    "            \n",
    "            # Try to fix common JSON issues before parsing\n",
    "            response_content = response_content.strip()\n",
    "            if response_content.startswith(\"```json\"):\n",
    "                response_content = response_content.replace(\"```json\", \"\", 1)\n",
    "            if response_content.endswith(\"```\"):\n",
    "                response_content = response_content.replace(\"```\", \"\", 1)\n",
    "            response_content = response_content.strip()\n",
    "            \n",
    "            eval_data = json.loads(response_content)\n",
    "            \n",
    "            # Create result dictionary using the original question to preserve all information\n",
    "            result = {'Question': question}\n",
    "            result[f'{criteria_config[\"name\"]} Score'] = eval_data['evaluations'][criteria_config[\"score_key\"]]\n",
    "            result[f'{criteria_config[\"name\"]} Justification'] = eval_data['evaluations'][criteria_config[\"justification_key\"]]\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON for question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content[:100]}...\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating question: {question[:50]}...\\nError: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
